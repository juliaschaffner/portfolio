{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0484d5ee-0a3e-4f46-a781-bea66f36939f",
   "metadata": {},
   "source": [
    "**Problem:** Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e32b3-d20d-4008-89a0-49071ecf609e",
   "metadata": {},
   "source": [
    "**Model:** Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323bb93-525e-42f1-b1c6-3ce0aeec37d3",
   "metadata": {},
   "source": [
    "**Group Members:** Julia Schaffner, Varun Popli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d232b-a629-4426-a0f4-4364a01e87a9",
   "metadata": {},
   "source": [
    "**Performance on Kaggle:** 113.75245"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa59f87-7c55-4db1-b222-16ea7c27ae01",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d8bb67-93fa-46e1-a896-3ee66577b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.35)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb441c-6811-48ef-b3bb-4c9b0b85962b",
   "metadata": {},
   "source": [
    "### Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef7730c-99b0-44c6-bb2d-002b57143f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_3468\\3638791601.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_train.price = data_train.price.str.replace('$', '').str.replace(',','').astype(float)\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_3468\\3638791601.py:17: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data_train = data_train.fillna(data_train.median())\n",
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_3468\\3638791601.py:23: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data_test = data_test.fillna(data_train.median())\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('train_regression.csv')\n",
    "\n",
    "# Clean and convert price\n",
    "data_train.price = data_train.price.str.replace('$', '').str.replace(',','').astype(float)\n",
    "\n",
    "# get rid of unrealistic value\n",
    "data_train = data_train[data_train.price < 10000]\n",
    "\n",
    "# Response rate\n",
    "data_train.host_response_rate = data_train.host_response_rate.str.replace('%','').astype(float)\n",
    "\n",
    "# Host acceptance rate\n",
    "data_train.host_acceptance_rate = data_train.host_acceptance_rate.str.replace('%','').astype(float)\n",
    "\n",
    "# Imputing numeric\n",
    "\n",
    "data_train = data_train.fillna(data_train.median())\n",
    "\n",
    "# apply everythingnto the test data\n",
    "data_test = pd.read_csv('test_regression.csv')\n",
    "data_test.host_response_rate = data_test.host_response_rate.str.replace('%','').astype(float)\n",
    "data_test.host_acceptance_rate = data_test.host_acceptance_rate.str.replace('%','').astype(float)\n",
    "data_test = data_test.fillna(data_train.median())\n",
    "\n",
    "# Host Total Listings Count\n",
    "data_train['host_total_listings_count'] = data_train['host_total_listings_count'].apply(lambda count: 1 if count <= 7 else 0)\n",
    "data_test['host_total_listings_count'] = data_test['host_total_listings_count'].apply(lambda count: 1 if count <= 7 else 0)\n",
    "\n",
    "# Host Response Time\n",
    "data_train['host_response_time'] = data_train['host_response_time'].apply(lambda time: 1 if time in ['within an hour', 'within a few hours'] else 0)\n",
    "data_test['host_response_time'] = data_test['host_response_time'].apply(lambda time: 1 if time in ['within an hour', 'within a few hours'] else 0)\n",
    "\n",
    "# Room Type\n",
    "data_train['room_type'] = data_train['room_type'].apply(lambda room: 1 if room in ['Private room', 'Entire home/apt', 'Hotel room'] else 0)\n",
    "data_test['room_type'] = data_test['room_type'].apply(lambda room: 1 if room in ['Private room', 'Entire home/apt', 'Hotel room'] else 0)\n",
    "\n",
    "# Property Type\n",
    "data_train['property_type'] = data_train['property_type'].apply(lambda location: 1 if location in ['Shared room in home', 'Shared room in bungalow', 'Shared room in hostel', 'Shared room in rental unit', 'Shared room in condo'] else 0)\n",
    "data_test['property_type'] = data_test['property_type'].apply(lambda location: 1 if location in ['Shared room in home', 'Shared room in bungalow', 'Shared room in hostel', 'Shared room in rental unit', 'Shared room in condo'] else 0)\n",
    "\n",
    "# Host Neighbourhood\n",
    "data_train['host_neighbourhood'] = data_train['host_neighbourhood'].apply(lambda neighborhood: 1 if neighborhood in ['Lakeview', 'Mount Greenwood', 'Gold Coast', 'Chicago Loop', 'Edison Park'] else 0)\n",
    "data_test['host_neighbourhood'] = data_test['host_neighbourhood'].apply(lambda neighborhood: 1 if neighborhood in ['Lakeview', 'Mount Greenwood', 'Gold Coast', 'Chicago Loop', 'Edison Park'] else 0)\n",
    "\n",
    "# Bathrooms Text\n",
    "data_train['bathrooms_text'] = data_train['bathrooms_text'].str.extract(r'(\\d+)').astype(float)\n",
    "data_test['bathrooms_text'] = data_test['bathrooms_text'].str.extract(r'(\\d+)').astype(float)\n",
    "data_train['bathrooms_text'] = data_train['bathrooms_text'].fillna(data_train['bathrooms_text'].median())\n",
    "data_test['bathrooms_text'] = data_test['bathrooms_text'].fillna(data_test['bathrooms_text'].median())\n",
    "\n",
    "\n",
    "# Convert float values to string\n",
    "data_train['host_location'] = data_train['host_location'].astype(str)\n",
    "data_test['host_location'] = data_test['host_location'].astype(str)\n",
    "\n",
    "# City list\n",
    "city_list = ['Chicago, IL', 'Lakeview', 'Mount Greenwood', 'Gold Coast', 'Chicago Loop', 'Edison Park']\n",
    "\n",
    "# Map locations to 'West' (1), 'East' (0), and NaN (0)\n",
    "data_train['host_location'] = data_train['host_location'].apply(lambda location: 1 if any(city in location for city in city_list) else (0 if location == 'nan' else 0))\n",
    "data_test['host_location'] = data_test['host_location'].apply(lambda location: 1 if any(city in location for city in city_list) else (0 if location == 'nan' else 0))\n",
    "\n",
    "# Map 't' to 1 and 'f' to 0 for binary columns\n",
    "data_train['host_is_superhost'] = data_train['host_is_superhost'].map({'t': 1, 'f': 0})\n",
    "data_test['host_is_superhost'] = data_test['host_is_superhost'].map({'t': 1, 'f': 0})\n",
    "\n",
    "data_train['host_has_profile_pic'] = data_train['host_has_profile_pic'].map({'t': 1, 'f': 0})\n",
    "data_test['host_has_profile_pic'] = data_test['host_has_profile_pic'].map({'t': 1, 'f': 0})\n",
    "\n",
    "data_train['host_identity_verified'] = data_train['host_identity_verified'].map({'t': 1, 'f': 0})\n",
    "data_test['host_identity_verified'] = data_test['host_identity_verified'].map({'t': 1, 'f': 0})\n",
    "\n",
    "data_train['has_availability'] = data_train['has_availability'].map({'t': 1, 'f': 0})\n",
    "data_test['has_availability'] = data_test['has_availability'].map({'t': 1, 'f': 0})\n",
    "\n",
    "data_train['instant_bookable'] = data_train['instant_bookable'].map({'t': 1, 'f': 0})\n",
    "data_test['instant_bookable'] = data_test['instant_bookable'].map({'t': 1, 'f': 0})\n",
    "\n",
    "# Extract email or phone verification from host_verifications\n",
    "data_train['host_verifications'] = data_train['host_verifications'].apply(lambda verifications: 1 if 'email' in verifications or 'phone' in verifications else 0)\n",
    "data_test['host_verifications'] = data_test['host_verifications'].apply(lambda verifications: 1 if 'email' in verifications or 'phone' in verifications else 0)\n",
    "\n",
    "# Map selected neighborhoods to 1 and others to 0\n",
    "neighborhoods_to_map_to_1 = ['Lake View', 'Lincoln Park', 'Near North Side', 'West Town', 'Logan Square']\n",
    "data_train['neighbourhood_cleansed'] = data_train['neighbourhood_cleansed'].apply(lambda neighborhood: 1 if neighborhood in neighborhoods_to_map_to_1 else 0)\n",
    "data_test['neighbourhood_cleansed'] = data_test['neighbourhood_cleansed'].apply(lambda neighborhood: 1 if neighborhood in neighborhoods_to_map_to_1 else 0)\n",
    "\n",
    "# Drop specified columns\n",
    "columns_to_exclude = ['host_id', 'host_since', 'first_review', 'last_review']\n",
    "data_train = data_train.drop(columns=columns_to_exclude, errors='ignore')\n",
    "data_test = data_test.drop(columns=columns_to_exclude, errors='ignore')\n",
    "\n",
    "# impute\n",
    "data_train = data_train.fillna(data_train.median())\n",
    "data_test = data_test.fillna(data_test.median())\n",
    "\n",
    "# select predictors and response\n",
    "X_train = data_train.drop(columns='price')\n",
    "y_train = data_train['price']\n",
    "\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0a3a4-93ba-4813-b61a-dd647b2c063c",
   "metadata": {},
   "source": [
    "### Predictor Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f091d5",
   "metadata": {},
   "source": [
    "No predictor selection was used in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d15423-033a-469f-a3a4-2bc454a27cc1",
   "metadata": {},
   "source": [
    "### Model Tuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48195e41-0de4-4b12-9f8f-2e7bca4ca12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating three base models - they are already tuned\n",
    "\n",
    "bm1 = RandomForestRegressor(max_features=7, max_samples=1.0, random_state=12, bootstrap = True)\n",
    "\n",
    "bm2 = XGBRegressor(random_state=12, objective='reg:squarederror', gamma = 1, learning_rate = 0.01, max_depth = 6, n_estimators = 1100, reg_lambda = 1, subsample = 0.75)\n",
    "\n",
    "bm3 = LGBMRegressor(random_state = 12, n_estimators = 980, colsample_bytree = 0.5, learning_rate = 0.01, max_depth = 10, reg_lambda = 1, subsample = 0.5, verbose = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fca491-c354-4eec-9755-1d17a9daf9c0",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ee40e7-f36c-42fe-82cb-dc6ec08c769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "preds = gscv.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with predictions and save it to a CSV file\n",
    "output = pd.DataFrame({'id': data_test.id, 'predicted': preds})\n",
    "output.to_csv('ensemble_regression_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
